{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "based on https://huggingface.co/ShinyQ/indobert-sentiment-analysis-indonesian-university-reviews"
      ],
      "metadata": {
        "id": "SBOlt0pqQ9hH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, math, random, csv\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict\n",
        "\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")\n",
        "from sklearn.metrics import classification_report, f1_score\n"
      ],
      "metadata": {
        "id": "a7Ui2I9YB_OP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8f00d1e-b0bb-4dbe-a358-c5e5449105cd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# --- Model checkpoint from Hugging Face ---\n",
        "MODEL_ID = \"indobenchmark/indobert-large-p2\"\n",
        "\n",
        "# --- Define 5 labels (adjust names to your dataset!)\n",
        "labels = ['anger', 'happy', 'sadness', 'love', 'fear']\n",
        "label2id: Dict[str, int] = {lb: i for i, lb in enumerate(labels)}\n",
        "id2label: Dict[int, str] = {i: lb for lb, i in label2id.items()}\n",
        "\n",
        "# --- Reproducibility ---\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "aN4f7D3cQVB3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    csv_path: str = \"Twitter_Emotion_Dataset.csv\"   # single file with text + label\n",
        "    epochs: int = 10\n",
        "    batch_size: int = 16\n",
        "    lr: float = 5e-5\n",
        "    max_len: int = 250\n",
        "    weight_decay: float = 0.01\n",
        "    warmup_ratio: float = 0.06\n",
        "    grad_clip: float = 1.0\n",
        "    num_workers: int = 2\n",
        "    val_ratio: float = 0.2          # 80% train / 20% val\n",
        "    out_dir: str = \"ckpt_unireviews_5labels\"\n",
        "\n",
        "cfg = Config()"
      ],
      "metadata": {
        "id": "f2uHPvvwQWu0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Indonesian stopwords\n",
        "stop_words = stopwords.words(\"indonesian\")\n"
      ],
      "metadata": {
        "id": "7E_X_ZzTk2A8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
        "    and remove words containing numbers.'''\n",
        "    # text = str(text).lower()\n",
        "    text = \" \".join([y for y in text.split() if y not in stop_words])\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "eFFyRk3jkaYb"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class CSVDataset(Dataset):\n",
        "    def __init__(self, csv_path: str, tokenizer, max_len: int):\n",
        "        self.rows = []\n",
        "        with open(csv_path, newline=\"\", encoding=\"utf-8\") as f:\n",
        "            reader = csv.DictReader(f)\n",
        "            for r in reader:\n",
        "                t = clean_text((r.get(\"tweet\") or \"\").strip())\n",
        "                y = (r.get(\"label\") or \"\").strip().lower()\n",
        "                if t and y in label2id:\n",
        "                    self.rows.append((t, label2id[y]))\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self): return len(self.rows)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text, y = self.rows[idx]\n",
        "        enc = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            padding=False,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
        "        item[\"labels\"] = torch.tensor(y, dtype=torch.long)\n",
        "        return item"
      ],
      "metadata": {
        "id": "-NLo9lvLQZcb"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch: List[Dict[str, torch.Tensor]]):\n",
        "    keys = [\"input_ids\", \"attention_mask\"]\n",
        "    if \"token_type_ids\" in batch[0]:\n",
        "        keys.append(\"token_type_ids\")\n",
        "    max_len = max(x[\"input_ids\"].size(0) for x in batch)\n",
        "    out = {}\n",
        "    for k in keys:\n",
        "        pad_id = tokenizer.pad_token_id if k == \"input_ids\" else 0\n",
        "        out[k] = torch.stack([\n",
        "            torch.nn.functional.pad(x[k], (0, max_len - x[k].size(0)), value=pad_id)\n",
        "            for x in batch\n",
        "        ])\n",
        "    out[\"labels\"] = torch.stack([x[\"labels\"] for x in batch])\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "XsdAtHWyQa_D"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    gold, pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            logits = model(**{k: v for k, v in batch.items() if k != \"labels\"}).logits\n",
        "            pred.extend(logits.argmax(-1).cpu().tolist())\n",
        "            gold.extend(batch[\"labels\"].cpu().tolist())\n",
        "    print(classification_report(gold, pred, target_names=labels, digits=4))\n"
      ],
      "metadata": {
        "id": "itYz16rmQeaM"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "\n",
        "    # --- Load dataset & split into train/val ---\n",
        "    full_ds = CSVDataset(cfg.csv_path, tokenizer, cfg.max_len)\n",
        "    n_val = int(len(full_ds) * cfg.val_ratio)\n",
        "    n_train = len(full_ds) - n_val\n",
        "    train_ds, val_ds = random_split(full_ds, [n_train, n_val])"
      ],
      "metadata": {
        "id": "8YF698Z8QhyT"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=cfg.batch_size,\n",
        "                          shuffle=True, num_workers=cfg.num_workers,\n",
        "                          collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_ds, batch_size=cfg.batch_size,\n",
        "                        shuffle=False, num_workers=cfg.num_workers,\n",
        "                        collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "XizNH00zQjbD"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Model ---\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_ID, num_labels=len(labels)\n",
        ")\n",
        "model.config.id2label = id2label\n",
        "model.config.label2id = label2id\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "_hBZpF_vQmGt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "706325aa-8bc6-4b3f-c165-33d398b6ba3d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-large-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-23): 24 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=1024, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Optimizer & scheduler ---\n",
        "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "grouped = [\n",
        "    {\"params\": [p for n,p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "      \"weight_decay\": cfg.weight_decay},\n",
        "    {\"params\": [p for n,p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "      \"weight_decay\": 0.0},\n",
        "]\n",
        "optimizer = torch.optim.AdamW(grouped, lr=cfg.lr)\n",
        "total_steps = cfg.epochs * math.ceil(len(train_loader))\n",
        "warmup_steps = int(cfg.warmup_ratio * total_steps)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps\n",
        ")"
      ],
      "metadata": {
        "id": "xf4OLJ11QnXU"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgaBL3G2QJj5",
        "outputId": "a5910ced-7eed-4289-ddcb-7b0d8d4f14a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "50it [00:32,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 step 50: loss 1.5654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100it [01:04,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 step 100: loss 1.0323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "150it [01:36,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 step 150: loss 0.7529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "200it [02:09,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 step 200: loss 0.8689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "221it [02:22,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Validation after epoch 1 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger     0.7898    0.6715    0.7258       207\n",
            "       happy     0.7262    0.8318    0.7754       220\n",
            "     sadness     0.6300    0.6528    0.6412       193\n",
            "        love     0.8761    0.7795    0.8250       127\n",
            "        fear     0.7698    0.8045    0.7868       133\n",
            "\n",
            "    accuracy                         0.7432       880\n",
            "   macro avg     0.7584    0.7480    0.7509       880\n",
            "weighted avg     0.7483    0.7432    0.7432       880\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "50it [00:32,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 step 50: loss 0.5136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100it [01:05,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 step 100: loss 0.4921\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "150it [01:36,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 step 150: loss 0.4781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "200it [02:09,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 step 200: loss 0.5413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "221it [02:22,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Validation after epoch 2 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger     0.7585    0.7585    0.7585       207\n",
            "       happy     0.8726    0.6227    0.7268       220\n",
            "     sadness     0.5776    0.8290    0.6809       193\n",
            "        love     0.8125    0.8189    0.8157       127\n",
            "        fear     0.9099    0.7594    0.8279       133\n",
            "\n",
            "    accuracy                         0.7489       880\n",
            "   macro avg     0.7862    0.7577    0.7619       880\n",
            "weighted avg     0.7780    0.7489    0.7523       880\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "50it [00:32,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 step 50: loss 0.1854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100it [01:04,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 step 100: loss 0.1842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "150it [01:37,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 step 150: loss 0.2105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "200it [02:09,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 step 200: loss 0.1796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "221it [02:22,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Validation after epoch 3 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger     0.7838    0.7005    0.7398       207\n",
            "       happy     0.8116    0.7636    0.7869       220\n",
            "     sadness     0.5920    0.7668    0.6682       193\n",
            "        love     0.8468    0.7402    0.7899       127\n",
            "        fear     0.8425    0.8045    0.8231       133\n",
            "\n",
            "    accuracy                         0.7523       880\n",
            "   macro avg     0.7753    0.7551    0.7616       880\n",
            "weighted avg     0.7667    0.7523    0.7557       880\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "50it [00:33,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 step 50: loss 0.0514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100it [01:04,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 step 100: loss 0.0576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "150it [01:36,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 step 150: loss 0.0667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "200it [02:09,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 step 200: loss 0.1173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "221it [02:22,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Validation after epoch 4 ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger     0.7184    0.8502    0.7788       207\n",
            "       happy     0.7725    0.8182    0.7947       220\n",
            "     sadness     0.6957    0.5803    0.6328       193\n",
            "        love     0.8291    0.7638    0.7951       127\n",
            "        fear     0.8226    0.7669    0.7938       133\n",
            "\n",
            "    accuracy                         0.7580       880\n",
            "   macro avg     0.7676    0.7559    0.7590       880\n",
            "weighted avg     0.7587    0.7580    0.7554       880\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "50it [00:32,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 step 50: loss 0.0145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100it [01:05,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 step 100: loss 0.0343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "150it [01:37,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 step 150: loss 0.0381\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "200it [02:09,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 step 200: loss 0.0289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "221it [02:23,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Validation after epoch 5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger     0.7778    0.7778    0.7778       207\n",
            "       happy     0.7283    0.8409    0.7806       220\n",
            "     sadness     0.6936    0.6218    0.6557       193\n",
            "        love     0.8571    0.8031    0.8293       127\n",
            "        fear     0.8110    0.7744    0.7923       133\n",
            "\n",
            "    accuracy                         0.7625       880\n",
            "   macro avg     0.7736    0.7636    0.7671       880\n",
            "weighted avg     0.7634    0.7625    0.7613       880\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "50it [00:33,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6 step 50: loss 0.0122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100it [01:05,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6 step 100: loss 0.0305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "150it [01:37,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6 step 150: loss 0.0056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "200it [02:09,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6 step 200: loss 0.0297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "221it [02:23,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Validation after epoch 6 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger     0.8168    0.7536    0.7839       207\n",
            "       happy     0.7883    0.7955    0.7919       220\n",
            "     sadness     0.6377    0.6839    0.6600       193\n",
            "        love     0.7846    0.8031    0.7938       127\n",
            "        fear     0.8231    0.8045    0.8137       133\n",
            "\n",
            "    accuracy                         0.7636       880\n",
            "   macro avg     0.7701    0.7681    0.7686       880\n",
            "weighted avg     0.7667    0.7636    0.7646       880\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "50it [00:31,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7 step 50: loss 0.0208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100it [01:02,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7 step 100: loss 0.0078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "150it [01:34,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7 step 150: loss 0.0114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "200it [02:07,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7 step 200: loss 0.0173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "221it [02:20,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Validation after epoch 7 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger     0.7981    0.8213    0.8095       207\n",
            "       happy     0.7895    0.8182    0.8036       220\n",
            "     sadness     0.6947    0.6839    0.6893       193\n",
            "        love     0.8125    0.8189    0.8157       127\n",
            "        fear     0.8512    0.7744    0.8110       133\n",
            "\n",
            "    accuracy                         0.7830       880\n",
            "   macro avg     0.7892    0.7833    0.7858       880\n",
            "weighted avg     0.7834    0.7830    0.7828       880\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "50it [00:31,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8 step 50: loss 0.0004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100it [01:02,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8 step 100: loss 0.0140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "150it [01:35,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8 step 150: loss 0.0012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "200it [02:07,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8 step 200: loss 0.0122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "221it [02:20,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Validation after epoch 8 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger     0.7808    0.8261    0.8028       207\n",
            "       happy     0.7845    0.8273    0.8053       220\n",
            "     sadness     0.7074    0.6891    0.6982       193\n",
            "        love     0.8203    0.8268    0.8235       127\n",
            "        fear     0.8850    0.7519    0.8130       133\n",
            "\n",
            "    accuracy                         0.7852       880\n",
            "   macro avg     0.7956    0.7842    0.7886       880\n",
            "weighted avg     0.7871    0.7852    0.7850       880\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "50it [00:31,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9 step 50: loss 0.0037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100it [01:02,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9 step 100: loss 0.0003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "150it [01:35,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9 step 150: loss 0.0079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "200it [02:07,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9 step 200: loss 0.0065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "221it [02:20,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Validation after epoch 9 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger     0.7919    0.7536    0.7723       207\n",
            "       happy     0.7867    0.8045    0.7955       220\n",
            "     sadness     0.6538    0.7047    0.6783       193\n",
            "        love     0.8125    0.8189    0.8157       127\n",
            "        fear     0.8443    0.7744    0.8078       133\n",
            "\n",
            "    accuracy                         0.7682       880\n",
            "   macro avg     0.7778    0.7712    0.7739       880\n",
            "weighted avg     0.7712    0.7682    0.7691       880\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "50it [00:32,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10 step 50: loss 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100it [01:02,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10 step 100: loss 0.0056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "150it [01:34,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10 step 150: loss 0.0021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "200it [02:06,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10 step 200: loss 0.0071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "221it [02:19,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Validation after epoch 10 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger     0.7902    0.7826    0.7864       207\n",
            "       happy     0.7876    0.8091    0.7982       220\n",
            "     sadness     0.6716    0.6995    0.6853       193\n",
            "        love     0.8154    0.8346    0.8249       127\n",
            "        fear     0.8644    0.7669    0.8127       133\n",
            "\n",
            "    accuracy                         0.7761       880\n",
            "   macro avg     0.7859    0.7785    0.7815       880\n",
            "weighted avg     0.7784    0.7761    0.7767       880\n",
            "\n",
            "\n",
            "Training done.\n"
          ]
        }
      ],
      "source": [
        "    # --- Training loop ---\n",
        "    os.makedirs(cfg.out_dir, exist_ok=True)\n",
        "    for epoch in range(1, cfg.epochs + 1):\n",
        "        model.train()\n",
        "        running = 0.0\n",
        "        for step, batch in tqdm(enumerate(train_loader, 1)):\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            out = model(**{k: v for k, v in batch.items() if k != \"labels\"},\n",
        "                        labels=batch[\"labels\"])\n",
        "            loss = out.loss\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
        "            optimizer.step(); scheduler.step(); optimizer.zero_grad()\n",
        "            running += loss.item()\n",
        "            if step % 50 == 0:\n",
        "                print(f\"epoch {epoch} step {step}: loss {running/50:.4f}\")\n",
        "                running = 0.0\n",
        "\n",
        "        print(f\"\\n=== Validation after epoch {epoch} ===\")\n",
        "        evaluate(model, val_loader, device)\n",
        "\n",
        "        save_path = os.path.join(cfg.out_dir, f\"epoch{epoch}\")\n",
        "        model.save_pretrained(save_path)\n",
        "        tokenizer.save_pretrained(save_path)\n",
        "\n",
        "    print(\"\\nTraining done.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SvM38JZRs_lz"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}