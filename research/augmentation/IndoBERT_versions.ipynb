{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezERtzrw0fe4",
        "outputId": "369ef289-6a59-49a4-84cc-75bdd9feb8bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from transformers import AutoTokenizer\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import os\n",
        "from nltk.corpus import stopwords\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrGqs7Yc0kCi"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ------------------------------\n",
        "# Config\n",
        "# ------------------------------\n",
        "MODEL_NAMES = [\"indobenchmark/indobert-large-p1\"]\n",
        "MODEL_NAME = \"indolem/indobertweet-base-uncased\"\n",
        "LABEL2INDEX = {'love': 0, 'anger': 1, 'sadness': 2, 'happy': 3, 'fear': 4}\n",
        "INDEX2LABEL = {v: k for k, v in LABEL2INDEX.items()}\n",
        "NUM_LABELS = len(LABEL2INDEX)\n",
        "MAX_LEN = 128\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 25\n",
        "LR = 2e-5\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "AUG_FRAC=0.2\n",
        "indo_stop_words = stopwords.words(fileids='indonesian')\n",
        "indo_stop_words.append(\"[USERNAME]\")\n",
        "indo_stop_words.append(\"url\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04W7XNTN0x0w"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Dataset Class\n",
        "# ------------------------------\n",
        "class TweetDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=MAX_LEN):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_len,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dN0-eod20zUY"
      },
      "outputs": [],
      "source": [
        "\n",
        "class IndoBertClassifier(nn.Module):\n",
        "    def __init__(self, model_name=MODEL_NAME,\n",
        "                 dense_1=64, dense_2=16, dropout=0.05, num_labels=5):\n",
        "        super(IndoBertClassifier, self).__init__()\n",
        "        self.bert = AutoModel.from_pretrained(model_name)\n",
        "        hidden_size = self.bert.config.hidden_size\n",
        "\n",
        "        # Layers according to your Keras architecture\n",
        "        self.pool = nn.AdaptiveMaxPool1d(1)   # GlobalMaxPool1D equivalent\n",
        "        self.fc1 = nn.Linear(hidden_size, dense_1)\n",
        "        self.drop1 = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(dense_1, dense_2)\n",
        "        self.fc3 = nn.Linear(dense_2, num_labels)\n",
        "        self.act_relu = nn.ReLU()\n",
        "        self.act_sigmoid = nn.Sigmoid()       # multi-label case\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        embeddings = outputs.last_hidden_state  # shape: (batch, seq_len, hidden)\n",
        "\n",
        "        # PyTorch pooling works on (N, C, L), so permute first\n",
        "        x = embeddings.permute(0, 2, 1)        # (batch, hidden, seq_len)\n",
        "        x = self.pool(x).squeeze(-1)           # (batch, hidden)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.act_relu(x)\n",
        "        x = self.drop1(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = self.act_relu(x)\n",
        "\n",
        "        logits = self.fc3(x)\n",
        "        out = self.act_sigmoid(logits)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiuyutkv01EO"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ------------------------------\n",
        "# Training & Evaluation Functions\n",
        "# ------------------------------\n",
        "def train_one_epoch(model, dataloader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    for batch in dataloader:\n",
        "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "        labels = batch[\"labels\"].to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(input_ids, attention_mask)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
        "    return total_loss / len(dataloader), acc, f1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlDgDFmF02fX"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "            attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "            labels = batch[\"labels\"].to(DEVICE)\n",
        "\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            loss = criterion(logits, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
        "    return total_loss / len(dataloader), acc, f1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "N_ICy4TNmvx8",
        "outputId": "015c87a7-3872-42d1-b856-5604ed677551"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0    label                                              tweet\n",
              "0            531    anger  Palembang, bersikap baik, jangan main-main den...\n",
              "1           4145  sadness  kl gabisa ngurus anak gausah punya anak sih ya...\n",
              "2           3815     fear  [USERNAME] [USERNAME] [USERNAME] Iya.. berbaga...\n",
              "3            891     love  seluruh hidup saya. saya dedikasikan dan saya ...\n",
              "4            485     fear  Ngasih tehaer ke keponakan. Baju dua biji cela...\n",
              "...          ...      ...                                                ...\n",
              "8357        3950  sadness  doi liat tadinya mau di bersihin ama doi tapi ...\n",
              "8358        2803    anger  apa tdk ada kata lain, yg dipelajari anak2 dis...\n",
              "8359        2755     love  [USERNAME] Couple saya juga ga pernah manggil ...\n",
              "8360        2815     love  Sampai salah satu pacar Anda pulang dan memint...\n",
              "8361        2449    happy  SUNDA KELAPA Alhamdulillah abis tarawih di Mas...\n",
              "\n",
              "[8362 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-232fa5a8-ac15-4111-be18-6373ea11b591\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>531</td>\n",
              "      <td>anger</td>\n",
              "      <td>Palembang, bersikap baik, jangan main-main den...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4145</td>\n",
              "      <td>sadness</td>\n",
              "      <td>kl gabisa ngurus anak gausah punya anak sih ya...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3815</td>\n",
              "      <td>fear</td>\n",
              "      <td>[USERNAME] [USERNAME] [USERNAME] Iya.. berbaga...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>891</td>\n",
              "      <td>love</td>\n",
              "      <td>seluruh hidup saya. saya dedikasikan dan saya ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>485</td>\n",
              "      <td>fear</td>\n",
              "      <td>Ngasih tehaer ke keponakan. Baju dua biji cela...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8357</th>\n",
              "      <td>3950</td>\n",
              "      <td>sadness</td>\n",
              "      <td>doi liat tadinya mau di bersihin ama doi tapi ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8358</th>\n",
              "      <td>2803</td>\n",
              "      <td>anger</td>\n",
              "      <td>apa tdk ada kata lain, yg dipelajari anak2 dis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8359</th>\n",
              "      <td>2755</td>\n",
              "      <td>love</td>\n",
              "      <td>[USERNAME] Couple saya juga ga pernah manggil ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8360</th>\n",
              "      <td>2815</td>\n",
              "      <td>love</td>\n",
              "      <td>Sampai salah satu pacar Anda pulang dan memint...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8361</th>\n",
              "      <td>2449</td>\n",
              "      <td>happy</td>\n",
              "      <td>SUNDA KELAPA Alhamdulillah abis tarawih di Mas...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8362 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-232fa5a8-ac15-4111-be18-6373ea11b591')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-232fa5a8-ac15-4111-be18-6373ea11b591 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-232fa5a8-ac15-4111-be18-6373ea11b591');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-291a8c3c-c98e-465b-a333-8f4d95030336\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-291a8c3c-c98e-465b-a333-8f4d95030336')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-291a8c3c-c98e-465b-a333-8f4d95030336 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_c510b3f7-d728-4340-806b-33266163a58c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c510b3f7-d728-4340-806b-33266163a58c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8362,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1271,\n        \"min\": 0,\n        \"max\": 4399,\n        \"num_unique_values\": 4181,\n        \"samples\": [\n          1648,\n          4254,\n          1922\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"sadness\",\n          \"happy\",\n          \"fear\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8326,\n        \"samples\": [\n          \"Dunia ini sulit ketika begitu lembut, bukan?\",\n          \"Aku menunggu kepulanganmu. #EXO #EXO_COMINGOON #TheElyXi On_dot #neexo [URL]\",\n          \"Hatiku selalu untuk dia, teman saya sendiri, dia adalah seorang pria yang ingin maju, cerdas, tidak perlu, sederhana, bersedia untuk menjadi teman dan bersedia untuk belajar dari siapa pun, mencintai ibunya sangat banyak, mengambil tanggung jawab penuh untuk keselamatannya, tidak pernah mengeluh.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "    # Read dataset (must have \"text\" and \"label\" columns)\n",
        "    df = pd.read_csv(\"train.csv\")\n",
        "    df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcglfCERRo8h"
      },
      "outputs": [],
      "source": [
        "\n",
        "    # df['tweet'] = df['tweet'].apply(lambda x: clean_text(x))\n",
        "    # df = augment_dataset(df, frac=AUG_FRAC)\n",
        "    df[\"label\"] = df[\"label\"].map(LABEL2INDEX)\n",
        "\n",
        "    texts = df[\"tweet\"].tolist()\n",
        "    labels = df[\"label\"].tolist()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fjgv4moKRrbg",
        "outputId": "7e13ecfb-354b-40a8-d79d-b4faf0d3fbb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "  Train Loss: 1.5672 | Acc: 0.3649 | F1: 0.2977\n",
            "  Val   Loss: 1.4971 | Acc: 0.5824 | F1: 0.5207\n",
            "Epoch 2/25\n",
            "  Train Loss: 1.4285 | Acc: 0.6488 | F1: 0.6405\n",
            "  Val   Loss: 1.3775 | Acc: 0.7209 | F1: 0.7165\n",
            "Epoch 3/25\n",
            "  Train Loss: 1.3063 | Acc: 0.7550 | F1: 0.7534\n",
            "  Val   Loss: 1.3034 | Acc: 0.7437 | F1: 0.7394\n",
            "Epoch 4/25\n",
            "  Train Loss: 1.1944 | Acc: 0.8276 | F1: 0.8258\n",
            "  Val   Loss: 1.2490 | Acc: 0.7585 | F1: 0.7564\n",
            "Epoch 5/25\n",
            "  Train Loss: 1.1125 | Acc: 0.8776 | F1: 0.8767\n",
            "  Val   Loss: 1.2096 | Acc: 0.7659 | F1: 0.7665\n",
            "Epoch 6/25\n",
            "  Train Loss: 1.0537 | Acc: 0.9090 | F1: 0.9084\n",
            "  Val   Loss: 1.1902 | Acc: 0.7702 | F1: 0.7698\n",
            "Epoch 7/25\n",
            "  Train Loss: 1.0142 | Acc: 0.9330 | F1: 0.9327\n",
            "  Val   Loss: 1.1812 | Acc: 0.7665 | F1: 0.7689\n",
            "Epoch 8/25\n",
            "  Train Loss: 0.9918 | Acc: 0.9430 | F1: 0.9429\n",
            "  Val   Loss: 1.1686 | Acc: 0.7690 | F1: 0.7671\n",
            "Epoch 9/25\n",
            "  Train Loss: 0.9804 | Acc: 0.9462 | F1: 0.9460\n",
            "  Val   Loss: 1.1632 | Acc: 0.7708 | F1: 0.7714\n",
            "Epoch 10/25\n",
            "  Train Loss: 0.9665 | Acc: 0.9550 | F1: 0.9549\n",
            "  Val   Loss: 1.1691 | Acc: 0.7566 | F1: 0.7574\n",
            "Epoch 11/25\n",
            "  Train Loss: 0.9639 | Acc: 0.9534 | F1: 0.9533\n",
            "  Val   Loss: 1.1488 | Acc: 0.7763 | F1: 0.7760\n",
            "Epoch 12/25\n",
            "  Train Loss: 0.9564 | Acc: 0.9589 | F1: 0.9588\n",
            "  Val   Loss: 1.1536 | Acc: 0.7690 | F1: 0.7653\n",
            "Epoch 13/25\n",
            "  Train Loss: 0.9503 | Acc: 0.9634 | F1: 0.9633\n",
            "  Val   Loss: 1.1598 | Acc: 0.7640 | F1: 0.7603\n",
            "Epoch 14/25\n",
            "  Train Loss: 0.9474 | Acc: 0.9643 | F1: 0.9642\n",
            "  Val   Loss: 1.1493 | Acc: 0.7628 | F1: 0.7656\n",
            "Epoch 15/25\n",
            "  Train Loss: 0.9444 | Acc: 0.9662 | F1: 0.9662\n",
            "  Val   Loss: 1.1430 | Acc: 0.7776 | F1: 0.7788\n",
            "Epoch 16/25\n",
            "  Train Loss: 0.9433 | Acc: 0.9664 | F1: 0.9663\n",
            "  Val   Loss: 1.1456 | Acc: 0.7727 | F1: 0.7717\n",
            "Epoch 17/25\n",
            "  Train Loss: 0.9410 | Acc: 0.9682 | F1: 0.9681\n",
            "  Val   Loss: 1.1586 | Acc: 0.7585 | F1: 0.7602\n",
            "Epoch 18/25\n",
            "  Train Loss: 0.9421 | Acc: 0.9661 | F1: 0.9660\n",
            "  Val   Loss: 1.1536 | Acc: 0.7628 | F1: 0.7597\n",
            "Epoch 19/25\n",
            "  Train Loss: 0.9437 | Acc: 0.9632 | F1: 0.9632\n",
            "  Val   Loss: 1.1445 | Acc: 0.7702 | F1: 0.7735\n",
            "Epoch 20/25\n",
            "  Train Loss: 0.9384 | Acc: 0.9694 | F1: 0.9693\n",
            "  Val   Loss: 1.1390 | Acc: 0.7770 | F1: 0.7760\n",
            "Epoch 21/25\n",
            "  Train Loss: 0.9367 | Acc: 0.9702 | F1: 0.9702\n",
            "  Val   Loss: 1.1366 | Acc: 0.7757 | F1: 0.7752\n"
          ]
        }
      ],
      "source": [
        "\n",
        "    for i, model in enumerate(MODEL_NAMES) :\n",
        "      tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "      dataset = TweetDataset(texts, labels, tokenizer)\n",
        "      # Split into train/val (80/20)\n",
        "      train_size = int(0.8 * len(dataset))\n",
        "      val_size = len(dataset) - train_size\n",
        "      train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "      train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "      val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "          # Model, Loss, Optimizer\n",
        "      model = IndoBertClassifier().to(DEVICE)\n",
        "      criterion = nn.CrossEntropyLoss()\n",
        "      optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "          # Training Loop\n",
        "      for epoch in range(EPOCHS):\n",
        "          train_loss, train_acc, train_f1 = train_one_epoch(model, train_loader, optimizer, criterion)\n",
        "          val_loss, val_acc, val_f1 = evaluate(model, val_loader, criterion)\n",
        "\n",
        "          print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
        "          print(f\"  Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | F1: {train_f1:.4f}\")\n",
        "          print(f\"  Val   Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | F1: {val_f1:.4f}\")\n",
        "\n",
        "      # Save Model\n",
        "      os.makedirs(\"saved_model\", exist_ok=True)\n",
        "      torch.save(model.state_dict(), f\"saved_model/model_{i}.pt\")\n",
        "      print(f\"Model saved to saved_model/model_{i}.pt\")\n",
        "      print(\"---------------------------------------------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \"indobenchmark/indobert-base-p1\"\n",
        "# Epoch 1/25\n",
        "#   Train Loss: 1.5805 | Acc: 0.3224 | F1: 0.2720\n",
        "#   Val   Loss: 1.5250 | Acc: 0.5690 | F1: 0.5375\n",
        "# Epoch 2/25\n",
        "#   Train Loss: 1.4280 | Acc: 0.6478 | F1: 0.6362\n",
        "#   Val   Loss: 1.3709 | Acc: 0.6707 | F1: 0.6737\n",
        "# Epoch 3/25\n",
        "#   Train Loss: 1.2843 | Acc: 0.7693 | F1: 0.7678\n",
        "#   Val   Loss: 1.2917 | Acc: 0.7101 | F1: 0.7099\n",
        "# Epoch 4/25\n",
        "#   Train Loss: 1.1860 | Acc: 0.8438 | F1: 0.8432\n",
        "#   Val   Loss: 1.2559 | Acc: 0.7065 | F1: 0.7092\n",
        "# Epoch 5/25\n",
        "#   Train Loss: 1.1079 | Acc: 0.9023 | F1: 0.9020\n",
        "#   Val   Loss: 1.2220 | Acc: 0.7256 | F1: 0.7272\n",
        "# Epoch 6/25\n",
        "#   Train Loss: 1.0565 | Acc: 0.9318 | F1: 0.9315\n",
        "#   Val   Loss: 1.2135 | Acc: 0.7185 | F1: 0.7213\n",
        "# Epoch 7/25\n",
        "#   Train Loss: 1.0246 | Acc: 0.9459 | F1: 0.9458\n",
        "#   Val   Loss: 1.1831 | Acc: 0.7394 | F1: 0.7418\n",
        "# Epoch 8/25\n",
        "#   Train Loss: 1.0016 | Acc: 0.9595 | F1: 0.9594\n",
        "#   Val   Loss: 1.2038 | Acc: 0.7095 | F1: 0.7135\n",
        "# Epoch 9/25\n",
        "#   Train Loss: 0.9869 | Acc: 0.9664 | F1: 0.9663\n",
        "#   Val   Loss: 1.1874 | Acc: 0.7203 | F1: 0.7236\n",
        "# Epoch 10/25\n",
        "#   Train Loss: 0.9758 | Acc: 0.9730 | F1: 0.9730\n",
        "#   Val   Loss: 1.1767 | Acc: 0.7256 | F1: 0.7260\n",
        "# Epoch 11/25\n",
        "#   Train Loss: 0.9688 | Acc: 0.9750 | F1: 0.9750\n",
        "#   Val   Loss: 1.1786 | Acc: 0.7298 | F1: 0.7312\n",
        "# Epoch 12/25\n",
        "#   Train Loss: 0.9621 | Acc: 0.9803 | F1: 0.9802\n",
        "#   Val   Loss: 1.1700 | Acc: 0.7322 | F1: 0.7300\n",
        "# Epoch 13/25\n",
        "#   Train Loss: 0.9566 | Acc: 0.9846 | F1: 0.9845\n",
        "#   Val   Loss: 1.1704 | Acc: 0.7322 | F1: 0.7355\n",
        "# Epoch 14/25\n",
        "#   Train Loss: 0.9540 | Acc: 0.9861 | F1: 0.9861\n",
        "#   Val   Loss: 1.1655 | Acc: 0.7340 | F1: 0.7350\n",
        "# Epoch 15/25\n",
        "#   Train Loss: 0.9523 | Acc: 0.9867 | F1: 0.9867\n",
        "#   Val   Loss: 1.1690 | Acc: 0.7256 | F1: 0.7276\n",
        "# Epoch 16/25\n",
        "#   Train Loss: 0.9484 | Acc: 0.9901 | F1: 0.9901\n",
        "#   Val   Loss: 1.1819 | Acc: 0.7161 | F1: 0.7180\n",
        "# Epoch 17/25\n",
        "#   Train Loss: 0.9468 | Acc: 0.9907 | F1: 0.9907\n",
        "#   Val   Loss: 1.1730 | Acc: 0.7274 | F1: 0.7276\n",
        "# Epoch 18/25\n",
        "#   Train Loss: 0.9440 | Acc: 0.9934 | F1: 0.9933\n",
        "#   Val   Loss: 1.1763 | Acc: 0.7256 | F1: 0.7293\n",
        "# Epoch 19/25\n",
        "#   Train Loss: 0.9414 | Acc: 0.9950 | F1: 0.9950\n",
        "#   Val   Loss: 1.1653 | Acc: 0.7322 | F1: 0.7333\n",
        "# Epoch 20/25\n",
        "#   Train Loss: 0.9400 | Acc: 0.9967 | F1: 0.9967\n",
        "#   Val   Loss: 1.1744 | Acc: 0.7250 | F1: 0.7260\n",
        "# Epoch 21/25\n",
        "#   Train Loss: 0.9409 | Acc: 0.9946 | F1: 0.9946\n",
        "#   Val   Loss: 1.1742 | Acc: 0.7221 | F1: 0.7271\n",
        "# Epoch 22/25\n",
        "#   Train Loss: 0.9389 | Acc: 0.9969 | F1: 0.9969\n",
        "#   Val   Loss: 1.1702 | Acc: 0.7292 | F1: 0.7318\n",
        "# Epoch 23/25\n",
        "#   Train Loss: 0.9409 | Acc: 0.9943 | F1: 0.9942\n",
        "#   Val   Loss: 1.1796 | Acc: 0.7215 | F1: 0.7254\n",
        "# Epoch 24/25\n",
        "#   Train Loss: 0.9388 | Acc: 0.9966 | F1: 0.9966\n",
        "#   Val   Loss: 1.1661 | Acc: 0.7340 | F1: 0.7339\n",
        "# Epoch 25/25\n",
        "#   Train Loss: 0.9385 | Acc: 0.9966 | F1: 0.9966\n",
        "#   Val   Loss: 1.1730 | Acc: 0.7274 | F1: 0.7306\n",
        "# Model saved to saved_model/model_0.pt\n",
        "# ---------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "n3fmR_MI_MvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \"indobenchmark/indobert-large-p1\"\n",
        "# Epoch 1/25\n",
        "#   Train Loss: 1.5672 | Acc: 0.3649 | F1: 0.2977\n",
        "#   Val   Loss: 1.4971 | Acc: 0.5824 | F1: 0.5207\n",
        "# Epoch 2/25\n",
        "#   Train Loss: 1.4285 | Acc: 0.6488 | F1: 0.6405\n",
        "#   Val   Loss: 1.3775 | Acc: 0.7209 | F1: 0.7165\n",
        "# Epoch 3/25\n",
        "#   Train Loss: 1.3063 | Acc: 0.7550 | F1: 0.7534\n",
        "#   Val   Loss: 1.3034 | Acc: 0.7437 | F1: 0.7394\n",
        "# Epoch 4/25\n",
        "#   Train Loss: 1.1944 | Acc: 0.8276 | F1: 0.8258\n",
        "#   Val   Loss: 1.2490 | Acc: 0.7585 | F1: 0.7564\n",
        "# Epoch 5/25\n",
        "#   Train Loss: 1.1125 | Acc: 0.8776 | F1: 0.8767\n",
        "#   Val   Loss: 1.2096 | Acc: 0.7659 | F1: 0.7665\n",
        "# Epoch 6/25\n",
        "#   Train Loss: 1.0537 | Acc: 0.9090 | F1: 0.9084\n",
        "#   Val   Loss: 1.1902 | Acc: 0.7702 | F1: 0.7698\n",
        "# Epoch 7/25\n",
        "#   Train Loss: 1.0142 | Acc: 0.9330 | F1: 0.9327\n",
        "#   Val   Loss: 1.1812 | Acc: 0.7665 | F1: 0.7689\n",
        "# Epoch 8/25\n",
        "#   Train Loss: 0.9918 | Acc: 0.9430 | F1: 0.9429\n",
        "#   Val   Loss: 1.1686 | Acc: 0.7690 | F1: 0.7671\n",
        "# Epoch 9/25\n",
        "#   Train Loss: 0.9804 | Acc: 0.9462 | F1: 0.9460\n",
        "#   Val   Loss: 1.1632 | Acc: 0.7708 | F1: 0.7714\n",
        "# Epoch 10/25\n",
        "#   Train Loss: 0.9665 | Acc: 0.9550 | F1: 0.9549\n",
        "#   Val   Loss: 1.1691 | Acc: 0.7566 | F1: 0.7574\n",
        "# Epoch 11/25\n",
        "#   Train Loss: 0.9639 | Acc: 0.9534 | F1: 0.9533\n",
        "#   Val   Loss: 1.1488 | Acc: 0.7763 | F1: 0.7760\n",
        "# Epoch 12/25\n",
        "#   Train Loss: 0.9564 | Acc: 0.9589 | F1: 0.9588\n",
        "#   Val   Loss: 1.1536 | Acc: 0.7690 | F1: 0.7653\n",
        "# Epoch 13/25\n",
        "#   Train Loss: 0.9503 | Acc: 0.9634 | F1: 0.9633\n",
        "#   Val   Loss: 1.1598 | Acc: 0.7640 | F1: 0.7603\n",
        "# Epoch 14/25\n",
        "#   Train Loss: 0.9474 | Acc: 0.9643 | F1: 0.9642\n",
        "#   Val   Loss: 1.1493 | Acc: 0.7628 | F1: 0.7656\n",
        "# Epoch 15/25\n",
        "#   Train Loss: 0.9444 | Acc: 0.9662 | F1: 0.9662\n",
        "#   Val   Loss: 1.1430 | Acc: 0.7776 | F1: 0.7788\n",
        "# Epoch 16/25\n",
        "#   Train Loss: 0.9433 | Acc: 0.9664 | F1: 0.9663\n",
        "#   Val   Loss: 1.1456 | Acc: 0.7727 | F1: 0.7717\n",
        "# Epoch 17/25\n",
        "#   Train Loss: 0.9410 | Acc: 0.9682 | F1: 0.9681\n",
        "#   Val   Loss: 1.1586 | Acc: 0.7585 | F1: 0.7602\n",
        "# Epoch 18/25\n",
        "#   Train Loss: 0.9421 | Acc: 0.9661 | F1: 0.9660\n",
        "#   Val   Loss: 1.1536 | Acc: 0.7628 | F1: 0.7597\n",
        "# Epoch 19/25\n",
        "#   Train Loss: 0.9437 | Acc: 0.9632 | F1: 0.9632\n",
        "#   Val   Loss: 1.1445 | Acc: 0.7702 | F1: 0.7735\n",
        "# Epoch 20/25\n",
        "#   Train Loss: 0.9384 | Acc: 0.9694 | F1: 0.9693\n",
        "#   Val   Loss: 1.1390 | Acc: 0.7770 | F1: 0.7760\n",
        "# Epoch 21/25\n",
        "#   Train Loss: 0.9367 | Acc: 0.9702 | F1: 0.9702\n",
        "#   Val   Loss: 1.1366 | Acc: 0.7757 | F1: 0.7752"
      ],
      "metadata": {
        "id": "D9OlHlnqN0jU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}