{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "based on https://huggingface.co/ShinyQ/indobert-sentiment-analysis-indonesian-university-reviews"
   ],
   "metadata": {
    "id": "SBOlt0pqQ9hH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os, math, random, csv\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict\n",
    "\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "from sklearn.metrics import classification_report, f1_score\n"
   ],
   "metadata": {
    "id": "a7Ui2I9YB_OP",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c8f00d1e-b0bb-4dbe-a358-c5e5449105cd"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# --- Model checkpoint from Hugging Face ---\n",
    "MODEL_ID = \"indobenchmark/indobert-large-p2\"\n",
    "\n",
    "# --- Define 5 labels (adjust names to your dataset!)\n",
    "labels = ['anger', 'happy', 'sadness', 'love', 'fear']\n",
    "label2id: Dict[str, int] = {lb: i for i, lb in enumerate(labels)}\n",
    "id2label: Dict[int, str] = {i: lb for lb, i in label2id.items()}\n",
    "\n",
    "# --- Reproducibility ---\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ],
   "metadata": {
    "id": "aN4f7D3cQVB3"
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    csv_path: str = \"Twitter_Emotion_Dataset.csv\"   # single file with text + label\n",
    "    epochs: int = 10\n",
    "    batch_size: int = 16\n",
    "    lr: float = 5e-5\n",
    "    max_len: int = 250\n",
    "    weight_decay: float = 0.01\n",
    "    warmup_ratio: float = 0.06\n",
    "    grad_clip: float = 1.0\n",
    "    num_workers: int = 2\n",
    "    val_ratio: float = 0.2          # 80% train / 20% val\n",
    "    out_dir: str = \"../ckpt_unireviews_5labels\"\n",
    "\n",
    "cfg = Config()"
   ],
   "metadata": {
    "id": "f2uHPvvwQWu0"
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Indonesian stopwords\n",
    "stop_words = stopwords.words(\"indonesian\")\n"
   ],
   "metadata": {
    "id": "7E_X_ZzTk2A8"
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    # text = str(text).lower()\n",
    "    text = \" \".join([y for y in text.split() if y not in stop_words])\n",
    "    return text\n"
   ],
   "metadata": {
    "id": "eFFyRk3jkaYb"
   },
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, csv_path: str, tokenizer, max_len: int):\n",
    "        self.rows = []\n",
    "        with open(csv_path, newline=\"\", encoding=\"utf-8\") as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for r in reader:\n",
    "                t = clean_text((r.get(\"tweet\") or \"\").strip())\n",
    "                y = (r.get(\"label\") or \"\").strip().lower()\n",
    "                if t and y in label2id:\n",
    "                    self.rows.append((t, label2id[y]))\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self): return len(self.rows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text, y = self.rows[idx]\n",
    "        enc = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            padding=False,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
    "        item[\"labels\"] = torch.tensor(y, dtype=torch.long)\n",
    "        return item"
   ],
   "metadata": {
    "id": "-NLo9lvLQZcb"
   },
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def collate_fn(batch: List[Dict[str, torch.Tensor]]):\n",
    "    keys = [\"input_ids\", \"attention_mask\"]\n",
    "    if \"token_type_ids\" in batch[0]:\n",
    "        keys.append(\"token_type_ids\")\n",
    "    max_len = max(x[\"input_ids\"].size(0) for x in batch)\n",
    "    out = {}\n",
    "    for k in keys:\n",
    "        pad_id = tokenizer.pad_token_id if k == \"input_ids\" else 0\n",
    "        out[k] = torch.stack([\n",
    "            torch.nn.functional.pad(x[k], (0, max_len - x[k].size(0)), value=pad_id)\n",
    "            for x in batch\n",
    "        ])\n",
    "    out[\"labels\"] = torch.stack([x[\"labels\"] for x in batch])\n",
    "    return out\n"
   ],
   "metadata": {
    "id": "XsdAtHWyQa_D"
   },
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    gold, pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            logits = model(**{k: v for k, v in batch.items() if k != \"labels\"}).logits\n",
    "            pred.extend(logits.argmax(-1).cpu().tolist())\n",
    "            gold.extend(batch[\"labels\"].cpu().tolist())\n",
    "    print(classification_report(gold, pred, target_names=labels, digits=4))\n"
   ],
   "metadata": {
    "id": "itYz16rmQeaM"
   },
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "\n",
    "    # --- Load dataset & bt_split into train/val ---\n",
    "    full_ds = CSVDataset(cfg.csv_path, tokenizer, cfg.max_len)\n",
    "    n_val = int(len(full_ds) * cfg.val_ratio)\n",
    "    n_train = len(full_ds) - n_val\n",
    "    train_ds, val_ds = random_split(full_ds, [n_train, n_val])"
   ],
   "metadata": {
    "id": "8YF698Z8QhyT"
   },
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=cfg.batch_size,\n",
    "                          shuffle=True, num_workers=cfg.num_workers,\n",
    "                          collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_ds, batch_size=cfg.batch_size,\n",
    "                        shuffle=False, num_workers=cfg.num_workers,\n",
    "                        collate_fn=collate_fn)"
   ],
   "metadata": {
    "id": "XizNH00zQjbD"
   },
   "execution_count": 42,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# --- Model ---\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_ID, num_labels=len(labels)\n",
    ")\n",
    "model.config.id2label = id2label\n",
    "model.config.label2id = label2id\n",
    "model.to(device)"
   ],
   "metadata": {
    "id": "_hBZpF_vQmGt",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "706325aa-8bc6-4b3f-c165-33d398b6ba3d"
   },
   "execution_count": 43,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-large-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# --- Optimizer & scheduler ---\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "grouped = [\n",
    "    {\"params\": [p for n,p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "      \"weight_decay\": cfg.weight_decay},\n",
    "    {\"params\": [p for n,p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "      \"weight_decay\": 0.0},\n",
    "]\n",
    "optimizer = torch.optim.AdamW(grouped, lr=cfg.lr)\n",
    "total_steps = cfg.epochs * math.ceil(len(train_loader))\n",
    "warmup_steps = int(cfg.warmup_ratio * total_steps)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps\n",
    ")"
   ],
   "metadata": {
    "id": "xf4OLJ11QnXU"
   },
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TgaBL3G2QJj5",
    "outputId": "a5910ced-7eed-4289-ddcb-7b0d8d4f14a6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "50it [00:32,  1.63it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 step 50: loss 1.5654\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100it [01:04,  1.60it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 step 100: loss 1.0323\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "150it [01:36,  1.60it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 step 150: loss 0.7529\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "200it [02:09,  1.58it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 step 200: loss 0.8689\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "221it [02:22,  1.55it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "=== Validation after epoch 1 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger     0.7898    0.6715    0.7258       207\n",
      "       happy     0.7262    0.8318    0.7754       220\n",
      "     sadness     0.6300    0.6528    0.6412       193\n",
      "        love     0.8761    0.7795    0.8250       127\n",
      "        fear     0.7698    0.8045    0.7868       133\n",
      "\n",
      "    accuracy                         0.7432       880\n",
      "   macro avg     0.7584    0.7480    0.7509       880\n",
      "weighted avg     0.7483    0.7432    0.7432       880\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "50it [00:32,  1.51it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 2 step 50: loss 0.5136\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100it [01:05,  1.47it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 2 step 100: loss 0.4921\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "150it [01:36,  1.51it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 2 step 150: loss 0.4781\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "200it [02:09,  1.51it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 2 step 200: loss 0.5413\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "221it [02:22,  1.55it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "=== Validation after epoch 2 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger     0.7585    0.7585    0.7585       207\n",
      "       happy     0.8726    0.6227    0.7268       220\n",
      "     sadness     0.5776    0.8290    0.6809       193\n",
      "        love     0.8125    0.8189    0.8157       127\n",
      "        fear     0.9099    0.7594    0.8279       133\n",
      "\n",
      "    accuracy                         0.7489       880\n",
      "   macro avg     0.7862    0.7577    0.7619       880\n",
      "weighted avg     0.7780    0.7489    0.7523       880\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "50it [00:32,  1.45it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 3 step 50: loss 0.1854\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100it [01:04,  1.61it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 3 step 100: loss 0.1842\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "150it [01:37,  1.57it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 3 step 150: loss 0.2105\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "200it [02:09,  1.58it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 3 step 200: loss 0.1796\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "221it [02:22,  1.55it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "=== Validation after epoch 3 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger     0.7838    0.7005    0.7398       207\n",
      "       happy     0.8116    0.7636    0.7869       220\n",
      "     sadness     0.5920    0.7668    0.6682       193\n",
      "        love     0.8468    0.7402    0.7899       127\n",
      "        fear     0.8425    0.8045    0.8231       133\n",
      "\n",
      "    accuracy                         0.7523       880\n",
      "   macro avg     0.7753    0.7551    0.7616       880\n",
      "weighted avg     0.7667    0.7523    0.7557       880\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "50it [00:33,  1.50it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 4 step 50: loss 0.0514\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100it [01:04,  1.54it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 4 step 100: loss 0.0576\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "150it [01:36,  1.57it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 4 step 150: loss 0.0667\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "200it [02:09,  1.46it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 4 step 200: loss 0.1173\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "221it [02:22,  1.55it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "=== Validation after epoch 4 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger     0.7184    0.8502    0.7788       207\n",
      "       happy     0.7725    0.8182    0.7947       220\n",
      "     sadness     0.6957    0.5803    0.6328       193\n",
      "        love     0.8291    0.7638    0.7951       127\n",
      "        fear     0.8226    0.7669    0.7938       133\n",
      "\n",
      "    accuracy                         0.7580       880\n",
      "   macro avg     0.7676    0.7559    0.7590       880\n",
      "weighted avg     0.7587    0.7580    0.7554       880\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "50it [00:32,  1.48it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 step 50: loss 0.0145\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100it [01:05,  1.59it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 step 100: loss 0.0343\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "150it [01:37,  1.68it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 step 150: loss 0.0381\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "200it [02:09,  1.66it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5 step 200: loss 0.0289\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "221it [02:23,  1.54it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "=== Validation after epoch 5 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger     0.7778    0.7778    0.7778       207\n",
      "       happy     0.7283    0.8409    0.7806       220\n",
      "     sadness     0.6936    0.6218    0.6557       193\n",
      "        love     0.8571    0.8031    0.8293       127\n",
      "        fear     0.8110    0.7744    0.7923       133\n",
      "\n",
      "    accuracy                         0.7625       880\n",
      "   macro avg     0.7736    0.7636    0.7671       880\n",
      "weighted avg     0.7634    0.7625    0.7613       880\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "50it [00:33,  1.50it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 6 step 50: loss 0.0122\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100it [01:05,  1.58it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 6 step 100: loss 0.0305\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "150it [01:37,  1.48it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 6 step 150: loss 0.0056\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "200it [02:09,  1.63it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 6 step 200: loss 0.0297\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "221it [02:23,  1.54it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "=== Validation after epoch 6 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger     0.8168    0.7536    0.7839       207\n",
      "       happy     0.7883    0.7955    0.7919       220\n",
      "     sadness     0.6377    0.6839    0.6600       193\n",
      "        love     0.7846    0.8031    0.7938       127\n",
      "        fear     0.8231    0.8045    0.8137       133\n",
      "\n",
      "    accuracy                         0.7636       880\n",
      "   macro avg     0.7701    0.7681    0.7686       880\n",
      "weighted avg     0.7667    0.7636    0.7646       880\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "50it [00:31,  1.58it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 7 step 50: loss 0.0208\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100it [01:02,  1.54it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 7 step 100: loss 0.0078\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "150it [01:34,  1.60it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 7 step 150: loss 0.0114\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "200it [02:07,  1.45it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 7 step 200: loss 0.0173\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "221it [02:20,  1.57it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "=== Validation after epoch 7 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger     0.7981    0.8213    0.8095       207\n",
      "       happy     0.7895    0.8182    0.8036       220\n",
      "     sadness     0.6947    0.6839    0.6893       193\n",
      "        love     0.8125    0.8189    0.8157       127\n",
      "        fear     0.8512    0.7744    0.8110       133\n",
      "\n",
      "    accuracy                         0.7830       880\n",
      "   macro avg     0.7892    0.7833    0.7858       880\n",
      "weighted avg     0.7834    0.7830    0.7828       880\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "50it [00:31,  1.44it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 8 step 50: loss 0.0004\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100it [01:02,  1.56it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 8 step 100: loss 0.0140\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "150it [01:35,  1.36it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 8 step 150: loss 0.0012\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "200it [02:07,  1.58it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 8 step 200: loss 0.0122\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "221it [02:20,  1.58it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "=== Validation after epoch 8 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger     0.7808    0.8261    0.8028       207\n",
      "       happy     0.7845    0.8273    0.8053       220\n",
      "     sadness     0.7074    0.6891    0.6982       193\n",
      "        love     0.8203    0.8268    0.8235       127\n",
      "        fear     0.8850    0.7519    0.8130       133\n",
      "\n",
      "    accuracy                         0.7852       880\n",
      "   macro avg     0.7956    0.7842    0.7886       880\n",
      "weighted avg     0.7871    0.7852    0.7850       880\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "50it [00:31,  1.60it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 9 step 50: loss 0.0037\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100it [01:02,  1.66it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 9 step 100: loss 0.0003\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "150it [01:35,  1.63it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 9 step 150: loss 0.0079\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "200it [02:07,  1.49it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 9 step 200: loss 0.0065\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "221it [02:20,  1.58it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "=== Validation after epoch 9 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger     0.7919    0.7536    0.7723       207\n",
      "       happy     0.7867    0.8045    0.7955       220\n",
      "     sadness     0.6538    0.7047    0.6783       193\n",
      "        love     0.8125    0.8189    0.8157       127\n",
      "        fear     0.8443    0.7744    0.8078       133\n",
      "\n",
      "    accuracy                         0.7682       880\n",
      "   macro avg     0.7778    0.7712    0.7739       880\n",
      "weighted avg     0.7712    0.7682    0.7691       880\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "50it [00:32,  1.50it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 10 step 50: loss 0.0002\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100it [01:02,  1.56it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 10 step 100: loss 0.0056\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "150it [01:34,  1.67it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 10 step 150: loss 0.0021\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "200it [02:06,  1.69it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 10 step 200: loss 0.0071\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "221it [02:19,  1.58it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "=== Validation after epoch 10 ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger     0.7902    0.7826    0.7864       207\n",
      "       happy     0.7876    0.8091    0.7982       220\n",
      "     sadness     0.6716    0.6995    0.6853       193\n",
      "        love     0.8154    0.8346    0.8249       127\n",
      "        fear     0.8644    0.7669    0.8127       133\n",
      "\n",
      "    accuracy                         0.7761       880\n",
      "   macro avg     0.7859    0.7785    0.7815       880\n",
      "weighted avg     0.7784    0.7761    0.7767       880\n",
      "\n",
      "\n",
      "Training done.\n"
     ]
    }
   ],
   "source": [
    "    # --- Training loop ---\n",
    "    os.makedirs(cfg.out_dir, exist_ok=True)\n",
    "    for epoch in range(1, cfg.epochs + 1):\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "        for step, batch in tqdm(enumerate(train_loader, 1)):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            out = model(**{k: v for k, v in batch.items() if k != \"labels\"},\n",
    "                        labels=batch[\"labels\"])\n",
    "            loss = out.loss\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
    "            optimizer.step(); scheduler.step(); optimizer.zero_grad()\n",
    "            running += loss.item()\n",
    "            if step % 50 == 0:\n",
    "                print(f\"epoch {epoch} step {step}: loss {running/50:.4f}\")\n",
    "                running = 0.0\n",
    "\n",
    "        print(f\"\\n=== Validation after epoch {epoch} ===\")\n",
    "        evaluate(model, val_loader, device)\n",
    "\n",
    "        save_path = os.path.join(cfg.out_dir, f\"epoch{epoch}\")\n",
    "        model.save_pretrained(save_path)\n",
    "        tokenizer.save_pretrained(save_path)\n",
    "\n",
    "    print(\"\\nTraining done.\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "SvM38JZRs_lz"
   },
   "execution_count": 13,
   "outputs": []
  }
 ]
}
